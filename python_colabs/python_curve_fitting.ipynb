{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to curve fitting in Python for Chemists\n",
        "\n",
        "This lesson aims to teach how to fit data in Python using the `SciPy` package. It is recommended that you have completed the [intro to Python Colab](https://colab.research.google.com/drive/1ltdsUiprT3O1kZIhEXF69ZJhHlqRPApx?usp=sharing) before attempting this one. The [data visualization Colab](https://colab.research.google.com/drive/1oWQn7g9zPEF605geLLMzfxOH7YOGH531?usp=sharing) may be helpful here as well but is not required.\n",
        "\n",
        "A few things to start:\n",
        "\n",
        "1.   These lessons only work in Google Chrome\n",
        "2.   If you want to save your progress, go to File> Save a Copy in Drive; then locate a spot in your Drive folder\n",
        "3.   You can save these notebooks and run offline as a Jupyter Notebook.\n",
        "\n",
        "If you have questions, feel free to contact Dr. Chris Berndsen in the JMU Chemistry Department.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kNHfBjryexlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Python packages\n",
        "Push the play button to load the python packages taking special note of how each package can be called by looking after the word \"as\"."
      ],
      "metadata": {
        "id": "AAUu8Pgifdnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KROk3T1SejNE"
      },
      "outputs": [],
      "source": [
        "# import the packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The data set we are going to import is from a set enzyme assays taken at several concentrations of the substrate. The data are absorbance measurements over time, which can be used to calculate the reaction rate at each substrate concentration. Ultimately, the data can be fitted to determine the Vmax and Kâ‚˜ value for the enzyme. There are several tasks to complete:\n",
        "\n",
        "\n",
        "\n",
        "1.   Plot the data to determine the appropriate time range to calculate the initial rate\n",
        "2.   Calculate the initial rate for each substrate concentration\n",
        "3.   Fit the initial rate data to the Michaelis-Menten equation\n",
        "4.   Plot the initial rate data and the fit\n",
        "\n",
        "There are several ways to approach these tasks and you are free to try a number of ways within the steps below. We expect that to complete these tasks you will likely use the `matplotlib`, `numpy`, `pandas`, and `scipy` packages and a `for` loop.\n",
        "\n"
      ],
      "metadata": {
        "id": "LRcWyVr4gAfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data from github\n",
        "url = 'https://raw.githubusercontent.com/CEBerndsen/chem_colab_data/main/ldh_kinetics_data.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# peek at the organization of the data\n",
        "# how many rows\n",
        "print(\"The data has\", len(df), \"rows\")\n",
        "\n",
        "\n",
        "\n",
        "# top 6 rows and columns\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lq-YsOCUghgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Viewing and cleaning the data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "diFuaeULWIQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data are imported, it is time to understand how the data can be fitted correctly. In enzyme kinetics, scientists use the initial rate, where the rate of the substrate production is linear with time. This is called the steady-state rate.\n",
        "\n",
        "Using `matplotlib`, make a plot of the data at the highest substrate concentration, the lowest substrate concentration, and one of the middle concentrations. The basic framework for the plot is in the box below, fill in the missing parts."
      ],
      "metadata": {
        "id": "_Q5ceYRB_-dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the data\n",
        "plt.plot(df['time'], ________, 'ro')\n",
        "plt.plot(__________, ________, 'bo')\n",
        "plt.plot(__________, ________, 'go')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3bNmak6UBBCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the plots above, it appears that product formation is linear with time until 60-100 seconds in. At the highest concentration, the data may not fully include the the steady-state, because the enzyme was catalyzing the reaction very quickly. We may remove this subset of the data later but will keep it in until we are certain.\n",
        "\n",
        "A good practice would be to view the data from substrate concentrations in the upper half of the range to know where the dataset begins to lose information on the enzyme steady-state.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Filtering the data\n",
        "\n",
        "To remove the data that occur after a certain time we need to indicate which column we will use and the condition we will use to indicate what rows to remove. In this case we want the `time` column and we want to keep the rows where time is < than the cutoff. We are making a subset of the original data where the data are linear.\n",
        "\n",
        "Fill in the blanks in the code below and then plot the data as above to confirm the data were removed correctly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6GgEalrOBKkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill in the blanks\n",
        "# blank one is the column name\n",
        "# blank two is a condition operator either >, <, or ==\n",
        "# blank three is the time value\n",
        "df2 = df[df['_______'] __ _____]\n",
        "\n",
        "# plot the data as above to confirm the filtering was done correctly.\n",
        "# remember to change the dataframe name if you just copy/paste the code from above!\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HZhwVIeqqdWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the filtering worked correctly, then the x axis should run from 0 to your cutoff value and each data set should be roughly linear. If either or both of those are not true, then check your code and try again.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Calculating the initial rates with a `for` loop\n",
        "\n",
        "Now that the data are reduced to just the data for calculating the inital rate, it is time to fit each data to a linear equation to determine the slope, which is equal to the rate. First we need to create the model or equation that we will fit to the data.\n",
        "\n",
        "The `SciPy` package contains a function called `curve_fit` which takes an equation, an x-values dataset, and a y-values dataset to determine the best fit. In the next code block, the equation is defined.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7w3kDe2rI52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the function or equation for curve_fit\n",
        "def lm_fit(time, m, b):\n",
        "    rate = m*time + b\n",
        "    return rate"
      ],
      "metadata": {
        "id": "19NrZoa2sdge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to isolate the time values as an array. This makes the 'for' loop we will construct in a moment a bit easier to write.\n",
        "\n",
        "Then create a list from the column values which are the concentrations. This will help later on when we create the dataframe with the results."
      ],
      "metadata": {
        "id": "JMLokxEmsjEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list from the time column\n",
        "conc = list(df2.columns.values)\n",
        "\n",
        "# create an array of concentration\n",
        "timearr = df2['time'].values"
      ],
      "metadata": {
        "id": "Sxyq3SaIsuhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create the `for` loop. This loop will iterate through the columns and fit the data to the equation `lm_fit` that was defined above. Curve_fit will produce the rate value (popt) and the covariance (pcov). The latter of which we will convert to the standard error. Then we will append the data to the respective empty lists."
      ],
      "metadata": {
        "id": "h7vfL53Xs6Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create empty lists to put the results\n",
        "rate = []\n",
        "error = []\n",
        "\n",
        "# loop through the columns and fit the data\n",
        "for i in ___.columns: # fill in the dataframe name\n",
        "    popt, pcov = curve_fit(lm_fit, _________, df2[i]) # fill in the column to use as x using df['____'], replace ____ with the column name\n",
        "    p_sigma = np.sqrt(np.diag(pcov)) # convert pcov to standard error\n",
        "    rate.append(popt[0]) # add the rate to the list\n",
        "    error.append(p_sigma[0]) # add the standard error to the list\n",
        "\n",
        "# assemble everything into a nice dataframe\n",
        "result_df = pd.DataFrame({'conc': conc,\n",
        "                          'rate': rate,\n",
        "                          'error': error})\n",
        "\n",
        "# view the results\n",
        "result_df.head()"
      ],
      "metadata": {
        "id": "Kc8-44tFtiBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result should show a dataframe with three columns, but something is wrong. The first concentration is time and the rate is just the correlation of time with time.\n",
        "\n",
        "To remove this row, we could filter the rows as we did before and remove everything with a rate of 1 or we can simply cut out the first row. The latter option is probably cleaner since we cannot be certain that there are not correct rows with a rate of 1.  \n",
        "The code for both methods is shown in the next block.\n"
      ],
      "metadata": {
        "id": "ky_Dk05wl7am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove those rows with rates equal to 1\n",
        "mm2 = result_df[result_df['rate'] != 1] # keep rows where the rate != (not equal) to 1\n",
        "mm2.head()\n",
        "\n",
        "# cut out the row\n",
        "mm = result_df.iloc[1:,:] # remember python starts with 0, we said keep row 1 to the end and all columns with [1:,:]\n",
        "mm.head()"
      ],
      "metadata": {
        "id": "A7kkaf-VwfGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's plot the data"
      ],
      "metadata": {
        "id": "sl37sRkXxWMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill in the column names from the mm to see how the rate varies with each concentration\n",
        "plt.plot(mm['_____'], mm['_____'], 'ro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gV0zAciZxbBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uh oh, this doesn't look correct. The x-axis labels are spaced as if the concentrations are text and not numbers. Check the type of data for each column. Ideally everything is an integer or a float, which means a number."
      ],
      "metadata": {
        "id": "QjOeF2UhxkQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mm.dtypes"
      ],
      "metadata": {
        "id": "lpJfz5lmx6bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The issue is when we did the for loop the time in the concentration column confused Python, so it made everything a character. Therefore, we need to convert the `conc` column to a number."
      ],
      "metadata": {
        "id": "DgNSfLwnx8Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mm['conc'] = pd.to_numeric(mm['conc'])\n",
        "mm.dtypes"
      ],
      "metadata": {
        "id": "7Q4Gg_EMy5ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything seems better now. Next we need to convert the rates from abs/sec to micromolar (uM) per second using Beer's law. We will also need to convert the error column from absorbance to uM using the same equation. The extinction coefficient is 6220 M-1 cm-1 and the pathlength is 0.2 cm. Then multiply by 1e6 to convert M to uM.\n",
        "\n",
        "Fill in the blanks to perform the conversion."
      ],
      "metadata": {
        "id": "6qZn1OmVzAkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column rate2 and error2 from the Beer's law coversion of rate and error\n",
        "mm['rate2'] = mm['_____'] # add in the Beer's law equation to convert\n",
        "mm['error2'] = mm['_____'] # add in the Beer's law equation to convert\n",
        "mm.head()"
      ],
      "metadata": {
        "id": "7hw8HCj6zQaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the data with rate2 on y-axis and conc on the x-axis to view the effect of substate concentration on the enzyme rate."
      ],
      "metadata": {
        "id": "NdXhCa4C0E3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the data\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jNV9_-6l0Slz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will fit the data to the Michaelis-Menten (M-M) equation by defining our equation and using curve_fit above. The M-M equation is\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# rate = (vmax*conc)/(k_m + conc)\n",
        "```\n",
        "Where vmax is the maximum rate of the enzyme, k_m is the concentration of substrate that results in 1/2 Vmax, and conc is the concentration of substrate. The data we have contains conc and the rate, thus we can fit this equation or model to the  data to calculate vmax and k_m.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The basic code is outlined below to help you. This time it is a bit easier since we do not need to use curve_fit and a for loop, just curve_fit."
      ],
      "metadata": {
        "id": "MUCWGhGi0WbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make the model for fitting\n",
        "def mm_fit(conc, v_max, k_m):\n",
        "    return (v_max*conc)/(k_m + conc) # we do not need to specify rate here\n",
        "\n",
        "# review curve fit from above, what values does it produce that we can put in the blanks?\n",
        "_______, ________ = curve_fit(mm_fit, ________, mm['rate'], # fill in the x data we will use\n",
        "                       sigma = mm['error'], # weight the data using the error column\n",
        "                       absolute_sigma = True) # it is absolute error\n",
        "\n",
        "\n",
        "print(\"The Vmax value is\", popt[0])\n",
        "print(\"The Km value is\", popt[1])"
      ],
      "metadata": {
        "id": "Xxe4dZoC03HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now plot the data with the fit:\n"
      ],
      "metadata": {
        "id": "L7CpQGx72jbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mm['conc'], mm['rate'], 'ro')\n",
        "plt.plot(mm['conc'], mm_fit(mm['conc'], *popt), 'g--',\n",
        "        label = 'fit: Vmax = %5.3f, Km = %5.3f' % tuple(popt))\n",
        "plt.errorbar(mm['conc'], mm['rate'], yerr = mm['error'], fmt = 'none')\n",
        "plt.xlabel('Concentration')\n",
        "plt.ylabel('Rate')\n",
        "plt.legend(loc = 4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZgxL6iw3A8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}